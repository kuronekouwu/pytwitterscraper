Metadata-Version: 2.1
Name: pytwitterscraper
Version: 1.2.2
Summary: Twitter Scraper using Python
Home-page: https://github.com/mrwan200/pytwitterscraper
Author: M-307
Author-email: contact@m-307.tk
License: UNKNOWN
Description: # Twitter Scraper Python
        Get data from twitter using REST API from Twitter :3
        
        # Prerequisites
        Before you begin, ensure you have met the following requirements:
        * Python 3.6
        * Internet Connnetion
        
        # Installation
        To install pytwitterscraper :
        
            pip install pytwitterscraper
        
        
        # Usage 
        First you have import libray pytwitterscraper :
            
            from pytwitterscraper import TwitterScraper
            
        
        and call class object TwitterScraper :
        
            tw = TwitterScraper()
        
        If you have step by step You have able to use pytwitterscraper
        
        # Class Object Data
        
        | Class Object Classes | Description |
        | ------ | ------ |
        | get_profile(name) | Get Profile from Twitter |
        | get_tweets(id,count=20) | Get List Tweet from Profille Twitter By ID |
        | get_tweetinfo(id,count=20) | Get Tweet Information By ID |
        | get_tweetcomments(id) | Get Tweet Comments By ID **Top 10 Comment** | 
        | get_trends() | Get Trend Hashtags **Detect with IP Location** |
        | searchkeywords(query) | Search Keyworld With Users and Topics |
        
        # Example Code
        1. Get Profile **Example : I want get profile from Shirakami Fubuki** :
            ```py 
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> profile = tw.get_profile("shirakamifubuki")
            >>> profile.__dict__
            >>> {'id': '997786053124616192', 'name': 'ç™½ä¸Šãƒ•ãƒ–ã‚­@ShirakamiFubuki', 'screenname': 'shirakamifubuki', 'url': 'https://twitter.com/shirakamifubuki', 'description': 'Vtuberäº‹å‹™æ‰€ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³/1æœŸç”Ÿç™½ä¸Šãƒ•ãƒ–ã‚­ðŸ¦Šâ–æ‹…å½“çµµå¸«:å‡ªç™½ã¿ã¨@lemon_mito ã€ãƒ„ã‚¤æ‹…å½“ã€‘ðŸ¦Šã¯é»’ä¸ŠðŸŒ½ã¯ãƒ¦ãƒ‹ã‚³ãƒ³ ã€çµµã€‘ï¼ƒçµµãƒ•ãƒ–ã‚­ ã€ç”Ÿæ”¾é€ã€‘#ãƒ•ãƒ–ã‚­ch ã€åˆ‡ã‚ŠæŠœãã€‘#ãƒ•ãƒ–åˆ‡ã‚Šã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‘#ç™½ä¸Šå¼æ‰‹æŠœãã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«', 'verifed': False, 'follower': 588788, 'following': 667, 'extended_url': 'https://t.co/R9TNhC7sPO', 'tweet': 75686, 'media': 9118, 'profileurl': 'https://pbs.twimg.com/profile_images/1322559849872334850/G2vq3G01.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_banners/997786053124616192/1594284737', 'createat': datetime.datetime(2018, 5, 19, 10, 28, 27, tzinfo=datetime.timezone.utc)}
            ```
        
        2. Get Tweet **Example : I want get tweets from Shirakami Fubuki** :
            ```py 
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> tweets = tw.get_tweets(997786053124616192, count=3)
            >>> tweets.contents
            >>> [{'id': 1313103613204467712, 'created_at': datetime.datetime(2020, 10, 5, 13, 7, 52, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': 'âœ¨ç™½ä¸Šãƒ•ãƒ–ã‚­ãŠèª•ç”Ÿæ—¥è¨˜å¿µãƒœã‚¤ã‚¹ï¼†ã‚°ãƒƒã‚ºâœ¨ãŠã‚‹ã‚„ã‚“ã‘ã®ã¬ã„ãã‚‹ã¿ã®å¤¢ãŒå¶ã„ã¾ã—ãŸãã—ã¦æ¹¯å‘‘ã‚‚ã„ã¤ã‹ä½œã‚ŠãŸã„ã¨è¨€ã£ã¦ãŸå¤¢ãŒå¶ã„ã¾ã—ãŸå¤¢ãŒæ²¢å±±è©°ã¾ã£ãŸã‚°ãƒƒã‚ºé”ã§ã™ã‚ˆã‚ã—ããŠã­ãŒã„ã—ã¾ã™ðŸŒ½ðŸ”½è³¼å…¥ã¯ã‚³ãƒãƒ©ðŸ”½â€¦ https://t.co/ZksPkhYQI2', 'hashtags': [], 'media': [], 'urls': [{'url': 'https://t.co/ZksPkhYQI2'}], 'likes': 8656, 'relay': 0, 'retweet': 2329}, {'id': 1325440832795635713, 'created_at': datetime.datetime(2020, 11, 8, 14, 11, 34, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': 'â°ï¼’ï¼•æ™‚ã‹ã‚‰\u3000ãƒãƒ«ãƒãƒ«ã¨ä¸€ç·’ã«å¹½éœŠèª¿ æŸ»ã„ãã“ã¨ã«ãªã£ãŸã‚ˆãƒ¼ãƒ¼ï¼ï¼ï¼ï¼âœ¨ä»Šã‚½ãƒ­ã§é ‘å¼µã£ã¦ã‚‹ã¿ãŸã„ãž(^ãƒ»Ï‰ãƒ»^Â§)ï¾‰ã€Phasmophobiaã€‘ æœ¬\u3000ç‰©\u3000ã®\u3000ç‹‚\u3000æ°— ã€å°¾ä¸¸ãƒãƒ«ã‚«/ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã€‘ https://t.co/MO7Xug3chb @YouTubeã‚ˆã‚Š', 'hashtags': [], 'media': [], 'urls': [{'url': 'https://t.co/MO7Xug3chb'}], 'likes': 1448, 'relay': 0, 'retweet': 254}, {'id': 1325458019069538304, 'created_at': datetime.datetime(2020, 11, 8, 15, 19, 52, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': 'â°ï¼’ï¼•æ™‚ã‹ã‚‰ï¼ï¼ï¼ï¼çªç™ºï¼ã‚­ãƒ„ãƒå±žã«ã‚ˆã‚‹ðŸŽªðŸŒ½âœ¨âœ¨Phasmophobiaâœ¨âœ¨å…ˆè¼©èª¿æŸ»å“¡ã¨ã—ã¦å¼•ã£å¼µã£ã¦ã„ããžã‰ãŠãŠã£ï¼ãƒãƒ«ãƒãƒ«ã‚‚ä¸Šæ‰‹ããªã£ã¦ã‚‹ã®ã§ï¼ï¼’äººã§ãƒ—ãƒ­èª¿æŸ»ã—ã«ã„ããžã‰ã‰ãŠã„ã£ï¼ï¼ï¼ðŸ”½å¾…æ©Ÿã—ã¦ãŠã‚‹ã‹ðŸ”½â€¦ https://t.co/2vUfw2RyY6', 'hashtags': [], 'media': [], 'urls': [{'url': 'https://t.co/2vUfw2RyY6'}], 'likes': 1707, 'relay': 0, 'retweet': 350}]
            ```
        
        3. Get Tweet Info **Example : I want to get info ID Tweet 1324993735248109568** :
            ```py
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> twinfo = tw.get_tweetinfo(1324993735248109568)
            >>> twinfo.contents
            >>> {'id': 1324993735248109568, 'created_at': datetime.datetime(2020, 11, 7, 8, 34, 58, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': 'â°ï¼’ï¼æ™‚ã‹ã‚‰ã§ã™ä»Šæ—¥ã®ãŠç¥ã„ã¯ï¼’ï¼æ™‚ã‹ã‚‰ã§ã™ï¼âœ¨ï¼’ï¼‘æ™‚ã¯ï¼•æœŸç”Ÿã‚³ãƒ©ãƒœã¿ãŸã„ã‹ã‚‰çš†ã§ã¿ã‚ˆãƒ¼ã£ðŸŒ½100ä¸‡äººã‚’ã¿ã‚“ãªã§ãŠç¥ã„ã™ã‚‹ã‚„ãƒ¼ã¤ðŸ”½ã„ã¤ã‚‚ã‚ã‚ŠãŒã¨ã£ðŸ”½ https://t.co/JV5IW889AE #ãƒ•ãƒ–ã‚­ch https://t.co/KSGTLDdnt3', 'hashtags': ['ãƒ•ãƒ–ã‚­ch'], 'media': [], 'urls': [], 'likes': 4204, 'relay': 0, 'retweet': 771}
            ```
        
        4. Get Tweet Comments **Example : I want to get comments from ID Tweet 1324993735248109568** :
            ```py
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> twcomments = tw.get_tweetcomments(1324993735248109568)
            >>> twcomments.contents
            >>> [{'id': 1324993789363056641, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 11, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki äº†è§£ã§ã™ï¼ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993879691599876, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 32, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki äº†è§£ã§ã™ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993879611904000, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 32, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ðŸ¥°ðŸ¥°ðŸ¥°ðŸ¥°ðŸ¥°ðŸ¥°', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993804059897857, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 14, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ã‚Šã‚‡ã´ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993901317529600, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 37, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ã‚Šã‚‡ã´ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993889401413632, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 35, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ã‚Šã‚‡ã´ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993901900386304, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 38, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki å¡¾ã§è¦‹ã‚Œã­ãƒ¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 1, 'relay': 0, 'retweet': 0}, {'id': 1324993880912064512, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 33, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ã‚Šã‚‡ã´ï¼ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993849077297155, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 25, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki äº†è§£ã§ã™ã€œï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993855440052225, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 26, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki I love you fubuki', 'hashtags': [], 'media': [], 'urls': [], 'likes': 1, 'relay': 0, 'retweet': 0}]
            ```
        
        5. Get Trends Twitter : 
            ```py
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> trends = tw.get_trends()
            >>> trends.content
            >>> [{'name': '#earthquake', 'description': None}, {'name': '#SundayMorning', 'description': 'Greeting a new day with grumpiness, enthusiasm, motivation and coffee'}, {'name': 'GOT7', 'description': None}, {'name': 'Newt', 'description': None}, {'name': '#SundayThoughts', 'description': 'Wisdom, inspiration and curiosity for your Sunday'}, {'name': '#sundayvibes', 'description': None}, {'name': '#AskFFT', 'description': None}, {'name': 'New Bedford', 'description': None}, {'name': 'Four Seasons Total Landscaping', 'description': "People express confusion after President Trump Tweets that a press conference will be held 'at Four Seasons Total Landscapingâ€™"}, {'name': 'Britain', 'description': None}, {'name': 'Antonio Brown', 'description': None}, {'name': 'Bliss Corner', 'description': None}, {'name': 'Good Sunday', 'description': None}, {'name': 'Cape Cod', 'description': None}, {'name': 'Parler', 'description': None}, {'name': 'Rudy', 'description': None}, {'name': 'Football Sunday', 'description': None}, {'name': 'Romney', 'description': None}, {'name': 'Deejay Dallas', 'description': None}, {'name': 'NFL Sunday', 'description': None}, {'name': 'USGS', 'description': None}, {'name': 'Written', 'description': None}, {'name': 'Mike Williams', 'description': None}, {'name': 'Turtwig', 'description': None}, {'name': 'Marvin Jones', 'description': None}, {'name': 'Chark', 'description': None}, {'name': 'Jeudy', 'description': None}, {'name': 'Doherty', 'description': None}, {'name': 'Seahawks -3', 'description': None}, {'name': 'Kushner', 'description': None}]
            ```
        
        6. Search Keyword :
            ```py
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> search = tw.searchkeywords("tokinosora")
            >>> trends.users
            >>> [{'name': 'æ™‚é‡Žç©ºäºº', 'url': 'https://twitter.com/TokinoSorahito', 'profileurl': 'http://pbs.twimg.com/profile_images/480667036410863616/yeHCL21U_normal.png', 'bannerurl': 'https://pbs.twimg.com/profile_images/480667036410863616/yeHCL21U_normal.png', 'screen_name': 'TokinoSorahito', 'tags': ['tokinosorahito', '@tokinosorahito', ' æ™‚é‡Žç©ºäºº']}, {'name': 'æ™‚ã®ç©º', 'url': 'https://twitter.com/tokinosora', 'profileurl': 'http://pbs.twimg.com/profile_images/584402675506098176/InsS4pO1_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/584402675506098176/InsS4pO1_normal.jpg', 'screen_name': 'tokinosora', 'tags': ['tokinosora', '@tokinosora', 'æ™‚ã®ç©º']}, {'name': 'ã¯ãƒ¼ã¨', 'url': 'https://twitter.com/tokinosora7nana', 'profileurl': 'http://pbs.twimg.com/profile_images/414496896229470208/65DNd-___normal.jpeg', 'bannerurl': 'https://pbs.twimg.com/profile_images/414496896229470208/65DNd-___normal.jpeg', 'screen_name': 'tokinosora7nana', 'tags': ['tokinosora7nana', '@tokinosora7nana', 'ã¯ãƒ¼ã¨']}, {'name': 'tokinosora111', 'url': 'https://twitter.com/tokinosora111', 'profileurl': 'http://pbs.twimg.com/profile_images/958098875058814976/jT0oYXLt_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/958098875058814976/jT0oYXLt_normal.jpg', 'screen_name': 'tokinosora111', 'tags': ['tokinosora111', '@tokinosora111']}, {'name': 'Tokinosora17', 'url': 'https://twitter.com/tokinosora17', 'profileurl': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'bannerurl': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'screen_name': 'tokinosora17', 'tags': ['tokinosora17', '@tokinosora17']}, {'name': 'æ¾é‡Ž', 'url': 'https://twitter.com/tokinosora33', 'profileurl': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'bannerurl': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'screen_name': 'tokinosora33', 'tags': ['tokinosora33', '@tokinosora33', 'æ¾é‡Ž']}, {'name': 'æ­¤å¸³æˆ¶åœç”¨ä¸­', 'url': 'https://twitter.com/tokinosora0705', 'profileurl': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'bannerurl': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'screen_name': 'tokinosora0705', 'tags': ['tokinosora0705', '@tokinosora0705', 'æ­¤å¸³æˆ¶åœç”¨ä¸­']}, {'name': 'å®™èˆ¹-ãã‚‰ãµã­-', 'url': 'https://twitter.com/tokinosorahune', 'profileurl': 'http://pbs.twimg.com/profile_images/749949021012172800/978S0ipS_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/749949021012172800/978S0ipS_normal.jpg', 'screen_name': 'tokinosorahune', 'tags': ['tokinosorahune', '@tokinosorahune', 'å®™èˆ¹-ãã‚‰ãµã­-']}]
            >>> trends.topics
            >>> []
            ```
        
        # Lastest 
        I have to thanks for source code from 
        - dgnsrekt 
        
         I have make some awsome project :3
        
        à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸™à¸µà¹‰... à¸‚à¸­à¹„à¸›à¸”à¹‰à¸§à¸¢à¸ à¸²à¸ž à¹€à¸¡à¸™à¸•à¸±à¸§à¹€à¸­à¸‡à¸¥à¹ˆà¸°à¸à¸±à¸™
        
        ![Fubuki F R I E N D](https://media1.tenor.com/images/0d99bbdd3327e45bb49262bc25a34997/tenor.gif)
        
        
        # License
        
        MIT
        
Keywords: pytwitterscraper,twitterscraper,webscraper,apiscraper
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
