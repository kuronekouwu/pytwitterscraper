Metadata-Version: 2.1
Name: pytwitterscraper
Version: 1.2.3
Summary: Twitter Scraper using Python
Home-page: https://github.com/mrwan200/pytwitterscraper
Author: M-307
Author-email: contact@m-307.tk
License: UNKNOWN
Description: # Twitter Scraper Python
        Get data from twitter using REST API from Twitter :3
        
        # Prerequisites
        Before you begin, ensure you have met the following requirements:
        * Python 3.6
        * Internet Connnetion
        
        # Installation
        To install pytwitterscraper :
        
            pip install pytwitterscraper
        
        
        # Usage 
        First you have import libray pytwitterscraper :
            
            from pytwitterscraper import TwitterScraper
            
        
        and call class object TwitterScraper :
        
            tw = TwitterScraper()
        
        If you have step by step You have able to use pytwitterscraper
        
        # Class Object Data
        
        | Class Object Classes | Description |
        | ------ | ------ |
        | get_profile(name=None,id=None) | Get Profile from Twitter **With select Name or ID |
        | get_tweets(id,count=20) | Get List Tweet from Profille Twitter By ID |
        | get_tweetinfo(id,count=20) | Get Tweet Information By ID |
        | get_tweetcomments(id) | Get Tweet Comments By ID **Top 10 Comment** | 
        | get_trends() | Get Trend Hashtags **Detect with IP Location** |
        | searchkeywords(query) | Search Keyworld With Users and Topics |
        
        # Example Code
        1. Get Profile **Example : I want get profile from Shirakami Fubuki** :
            ```py 
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> profile = tw.get_profile(name="shirakamifubuki")
            >>> profile.__dict__
            >>> {'id': '997786053124616192', 'name': 'ç™½ä¸Šãƒ•ãƒ–ã‚­@ShirakamiFubuki', 'screen_name': 'shirakamifubuki', 'url': 'https://twitter.com/shirakamifubuki', 'description': 'Vtuberäº‹å‹™æ‰€ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³/1æœŸç”Ÿç™½ä¸Šãƒ•ãƒ–ã‚­ðŸ¦Šâ–æ‹…å½“çµµå¸«:å‡ªç™½ã¿ã¨@lemon_mito ã€ãƒ„ã‚¤æ‹…å½“ã€‘ðŸ¦Šã¯é»’ä¸ŠðŸŒ½ã¯ãƒ¦ãƒ‹ã‚³ãƒ³ ã€çµµã€‘ï¼ƒçµµãƒ•ãƒ–ã‚­ ã€ç”Ÿæ”¾é€ã€‘#ãƒ•ãƒ–ã‚­ch ã€åˆ‡ã‚ŠæŠœãã€‘#ãƒ•ãƒ–åˆ‡ã‚Šã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‘#ç™½ä¸Šå¼æ‰‹æŠœãã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«', 'location': 'èª•ç”Ÿæ—¥\u3000ï¼‘ï¼æœˆï¼•æ—¥/ãƒ„ã‚¤ã‚¹ãƒ†æ²¼ðŸ™ã‚¢ãƒ¼ã‚¯ãƒŠã‚¤ãƒ„æ²¼/FGOæ²¼', 'verifed': False, 'follower': 589583, 'following': 668, 'extended_url': 'https://t.co/R9TNhC7sPO', 'tweet': 75702, 'media': 9120, 'profileurl': 'https://pbs.twimg.com/profile_images/1322559849872334850/G2vq3G01.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_banners/997786053124616192/1594284737', 'createat': datetime.datetime(2018, 5, 19, 10, 28, 27, tzinfo=datetime.timezone.utc)}
            ```
        
        2. Get Profile **Example : I want get profile from ID 880317891249188864** :
            ```py 
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> profile = tw.get_profile(name="shirakamifubuki")
            >>> profile.__dict__
            >>> {'id': '880317891249188864', 'name': 'ã¨ãã®ãã‚‰ðŸ»11/29.2ndLIVEãƒ‘ãƒ©ãƒ¬ãƒ«ã‚¿ã‚¤ãƒ ï¼', 'screen_name': 'tokino_sora', 'url': 'https://twitter.com/tokino_sora', 'description': 'ðŸŽŠ 2ndã‚¢ãƒ«ãƒãƒ ã€ŽON STAGE!ã€ãƒ“ã‚¯ã‚¿ãƒ¼ã‚¨ãƒ³ã‚¿ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‚ˆã‚Šå¥½è©•ç™ºå£²ä¸­ï¼ðŸŽ‰11/29ã¨ãã®ãã‚‰2ndLIVEã€Žãƒ‘ãƒ©ãƒ¬ãƒ«ã‚¿ã‚¤ãƒ ã€é–‹å‚¬æ±ºå®šï¼ï¼ðŸ»ãƒãƒ¼ãƒãƒ£ãƒ«ã‚¢ã‚¤ãƒ‰ãƒ«ã¨ãã®ãã‚‰(à¹‘â•¹á†ºâ•¹)æ¨ªã‚¢ãƒªç›®æŒ‡ã—ã¦ãŒã‚“ã°ã‚Šã¾ã™à­§(à¹‘â€¢Ì€ã…â€¢Ìà¹‘)à«­âœ§â£ï¸#ã¨ãã®ãã‚‰,#ã¨ãã®ãã‚‰ç”Ÿæ”¾é€,#soraArt', 'location': 'æ—¥æœ¬ æ±äº¬', 'verifed': None, 'follower': 318548, 'following': 7123, 'extended_url': 'https://t.co/YVd92xsmZA', 'tweet': 19794, 'media': 1887, 'profileurl': 'https://pbs.twimg.com/profile_images/1296434665016844288/2RqmlpoD.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_banners/880317891249188864/1602301415', 'createat': datetime.datetime(2017, 6, 29, 6, 51, 55, tzinfo=datetime.timezone.utc)}
            ```
        
        3. Get Tweet **Example : I want get tweets from Shirakami Fubuki** :
            ```py 
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> tweets = tw.get_tweets(997786053124616192, count=3)
            >>> tweets.contents
            >>> [{'id': 1313103613204467712, 'created_at': datetime.datetime(2020, 10, 5, 13, 7, 52, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': 'âœ¨ç™½ä¸Šãƒ•ãƒ–ã‚­ãŠèª•ç”Ÿæ—¥è¨˜å¿µãƒœã‚¤ã‚¹ï¼†ã‚°ãƒƒã‚ºâœ¨ãŠã‚‹ã‚„ã‚“ã‘ã®ã¬ã„ãã‚‹ã¿ã®å¤¢ãŒå¶ã„ã¾ã—ãŸãã—ã¦æ¹¯å‘‘ã‚‚ã„ã¤ã‹ä½œã‚ŠãŸã„ã¨è¨€ã£ã¦ãŸå¤¢ãŒå¶ã„ã¾ã—ãŸå¤¢ãŒæ²¢å±±è©°ã¾ã£ãŸã‚°ãƒƒã‚ºé”ã§ã™ã‚ˆã‚ã—ããŠã­ãŒã„ã—ã¾ã™ðŸŒ½ðŸ”½è³¼å…¥ã¯ã‚³ãƒãƒ©ðŸ”½â€¦ https://t.co/ZksPkhYQI2', 'hashtags': [], 'media': [], 'urls': [{'url': 'https://t.co/ZksPkhYQI2'}], 'likes': 8656, 'relay': 0, 'retweet': 2329}, {'id': 1325440832795635713, 'created_at': datetime.datetime(2020, 11, 8, 14, 11, 34, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': 'â°ï¼’ï¼•æ™‚ã‹ã‚‰\u3000ãƒãƒ«ãƒãƒ«ã¨ä¸€ç·’ã«å¹½éœŠèª¿ æŸ»ã„ãã“ã¨ã«ãªã£ãŸã‚ˆãƒ¼ãƒ¼ï¼ï¼ï¼ï¼âœ¨ä»Šã‚½ãƒ­ã§é ‘å¼µã£ã¦ã‚‹ã¿ãŸã„ãž(^ãƒ»Ï‰ãƒ»^Â§)ï¾‰ã€Phasmophobiaã€‘ æœ¬\u3000ç‰©\u3000ã®\u3000ç‹‚\u3000æ°— ã€å°¾ä¸¸ãƒãƒ«ã‚«/ãƒ›ãƒ­ãƒ©ã‚¤ãƒ–ã€‘ https://t.co/MO7Xug3chb @YouTubeã‚ˆã‚Š', 'hashtags': [], 'media': [], 'urls': [{'url': 'https://t.co/MO7Xug3chb'}], 'likes': 1448, 'relay': 0, 'retweet': 254}, {'id': 1325458019069538304, 'created_at': datetime.datetime(2020, 11, 8, 15, 19, 52, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': 'â°ï¼’ï¼•æ™‚ã‹ã‚‰ï¼ï¼ï¼ï¼çªç™ºï¼ã‚­ãƒ„ãƒå±žã«ã‚ˆã‚‹ðŸŽªðŸŒ½âœ¨âœ¨Phasmophobiaâœ¨âœ¨å…ˆè¼©èª¿æŸ»å“¡ã¨ã—ã¦å¼•ã£å¼µã£ã¦ã„ããžã‰ãŠãŠã£ï¼ãƒãƒ«ãƒãƒ«ã‚‚ä¸Šæ‰‹ããªã£ã¦ã‚‹ã®ã§ï¼ï¼’äººã§ãƒ—ãƒ­èª¿æŸ»ã—ã«ã„ããžã‰ã‰ãŠã„ã£ï¼ï¼ï¼ðŸ”½å¾…æ©Ÿã—ã¦ãŠã‚‹ã‹ðŸ”½â€¦ https://t.co/2vUfw2RyY6', 'hashtags': [], 'media': [], 'urls': [{'url': 'https://t.co/2vUfw2RyY6'}], 'likes': 1707, 'relay': 0, 'retweet': 350}]
            ```
        
        4. Get Tweet Info **Example : I want to get info ID Tweet 1324993735248109568** :
            ```py
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> twinfo = tw.get_tweetinfo(1324993735248109568)
            >>> twinfo.contents
            >>> {'id': 1324993735248109568, 'created_at': datetime.datetime(2020, 11, 7, 8, 34, 58, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': 'â°ï¼’ï¼æ™‚ã‹ã‚‰ã§ã™ä»Šæ—¥ã®ãŠç¥ã„ã¯ï¼’ï¼æ™‚ã‹ã‚‰ã§ã™ï¼âœ¨ï¼’ï¼‘æ™‚ã¯ï¼•æœŸç”Ÿã‚³ãƒ©ãƒœã¿ãŸã„ã‹ã‚‰çš†ã§ã¿ã‚ˆãƒ¼ã£ðŸŒ½100ä¸‡äººã‚’ã¿ã‚“ãªã§ãŠç¥ã„ã™ã‚‹ã‚„ãƒ¼ã¤ðŸ”½ã„ã¤ã‚‚ã‚ã‚ŠãŒã¨ã£ðŸ”½ https://t.co/JV5IW889AE #ãƒ•ãƒ–ã‚­ch https://t.co/KSGTLDdnt3', 'hashtags': ['ãƒ•ãƒ–ã‚­ch'], 'media': [], 'urls': [], 'likes': 4204, 'relay': 0, 'retweet': 771}
            ```
        
        5. Get Tweet Comments **Example : I want to get comments from ID Tweet 1324993735248109568** :
            ```py
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> twcomments = tw.get_tweetcomments(1324993735248109568)
            >>> twcomments.contents
            >>> [{'id': 1324993789363056641, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 11, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki äº†è§£ã§ã™ï¼ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993879691599876, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 32, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki äº†è§£ã§ã™ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993879611904000, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 32, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ðŸ¥°ðŸ¥°ðŸ¥°ðŸ¥°ðŸ¥°ðŸ¥°', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993804059897857, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 14, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ã‚Šã‚‡ã´ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993901317529600, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 37, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ã‚Šã‚‡ã´ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993889401413632, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 35, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ã‚Šã‚‡ã´ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993901900386304, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 38, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki å¡¾ã§è¦‹ã‚Œã­ãƒ¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 1, 'relay': 0, 'retweet': 0}, {'id': 1324993880912064512, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 33, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ã‚Šã‚‡ã´ï¼ï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993849077297155, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 25, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki äº†è§£ã§ã™ã€œï¼', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993855440052225, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 26, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki I love you fubuki', 'hashtags': [], 'media': [], 'urls': [], 'likes': 1, 'relay': 0, 'retweet': 0}]
            ```
        
        6. Get Lasest Trends Twitter : 
            ```py
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> trends = tw.get_trends()
            >>> trends.content
            >>> [{'name': '#earthquake', 'description': None}, {'name': '#SundayMorning', 'description': 'Greeting a new day with grumpiness, enthusiasm, motivation and coffee'}, {'name': 'GOT7', 'description': None}, {'name': 'Newt', 'description': None}, {'name': '#SundayThoughts', 'description': 'Wisdom, inspiration and curiosity for your Sunday'}, {'name': '#sundayvibes', 'description': None}, {'name': '#AskFFT', 'description': None}, {'name': 'New Bedford', 'description': None}, {'name': 'Four Seasons Total Landscaping', 'description': "People express confusion after President Trump Tweets that a press conference will be held 'at Four Seasons Total Landscapingâ€™"}, {'name': 'Britain', 'description': None}, {'name': 'Antonio Brown', 'description': None}, {'name': 'Bliss Corner', 'description': None}, {'name': 'Good Sunday', 'description': None}, {'name': 'Cape Cod', 'description': None}, {'name': 'Parler', 'description': None}, {'name': 'Rudy', 'description': None}, {'name': 'Football Sunday', 'description': None}, {'name': 'Romney', 'description': None}, {'name': 'Deejay Dallas', 'description': None}, {'name': 'NFL Sunday', 'description': None}, {'name': 'USGS', 'description': None}, {'name': 'Written', 'description': None}, {'name': 'Mike Williams', 'description': None}, {'name': 'Turtwig', 'description': None}, {'name': 'Marvin Jones', 'description': None}, {'name': 'Chark', 'description': None}, {'name': 'Jeudy', 'description': None}, {'name': 'Doherty', 'description': None}, {'name': 'Seahawks -3', 'description': None}, {'name': 'Kushner', 'description': None}]
            ```
        
        7. Search Keyword :
            ```py
            >>> from pytwitterscraper import TwitterScraper
            >>> tw = TwitterScraper()
            >>> search = tw.searchkeywords("tokino_sora")
            >>> trends.users
            >>> [{'name': 'ã¨ãã®ãã‚‰ðŸ»11/29.2ndLIVEãƒ‘ãƒ©ãƒ¬ãƒ«ã‚¿ã‚¤ãƒ ï¼', 'url': 'https://twitter.com/tokino_sora', 'profileurl': 'http://pbs.twimg.com/profile_images/1296434665016844288/2RqmlpoD_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/1296434665016844288/2RqmlpoD_normal.jpg', 'screen_name': 'tokino_sora', 'tags': ['tokino_sora', '@tokino_sora', 'tokino', 'sora', 'ã¨ãã®ãã‚‰ðŸ»11/29.2ndliveãƒ‘ãƒ©ãƒ¬ãƒ«ã‚¿ã‚¤ãƒ !']}, {'name': 'æ™‚é‡Žç©ºäºº', 'url': 'https://twitter.com/TokinoSorahito', 'profileurl': 'http://pbs.twimg.com/profile_images/480667036410863616/yeHCL21U_normal.png', 'bannerurl': 'https://pbs.twimg.com/profile_images/480667036410863616/yeHCL21U_normal.png', 'screen_name': 'TokinoSorahito', 'tags': ['tokinosorahito', '@tokinosorahito', 'æ™‚é‡Žç©ºäºº']}, {'name': 'Tokino Sora', 'url': 'https://twitter.com/TokinoSora25', 'profileurl': 'http://pbs.twimg.com/profile_images/1320705788218765313/xDbzLV47_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/1320705788218765313/xDbzLV47_normal.jpg', 'screen_name': 'TokinoSora25', 'tags': ['tokinosora25', '@tokinosora25', 'tokino', 'sora']}, {'name': 'Neil Qu', 'url': 'https://twitter.com/TokinoSoraFan', 'profileurl': 'http://pbs.twimg.com/profile_images/1222368653758255104/cmvSX51v_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/1222368653758255104/cmvSX51v_normal.jpg', 'screen_name': 'TokinoSoraFan', 'tags': ['tokinosorafan', '@tokinosorafan', 'neil', 'qu']}, {'name': "tokino sora's camera stand", 'url': 'https://twitter.com/randomrubeee', 'profileurl': 'http://pbs.twimg.com/profile_images/1325110251356643331/S6ctgUp0_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/1325110251356643331/S6ctgUp0_normal.jpg', 'screen_name': 'randomrubeee', 'tags': ['randomrubeee', '@randomrubeee', 'tokino', "sora's", 'camera', 'stand']}, {'name': 'Simp 4 Tokino Sora', 'url': 'https://twitter.com/kalatnieufene', 'profileurl': 'http://pbs.twimg.com/profile_images/1281801965815517185/DDaYI5yo_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/1281801965815517185/DDaYI5yo_normal.jpg', 'screen_name': 'kalatnieufene', 'tags': ['kalatnieufene', '@kalatnieufene', 'simp', '4', 'tokino', 'sora']}, {'name': 'sora tokino', 'url': 'https://twitter.com/sora_tokino', 'profileurl': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'bannerurl': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'screen_name': 'sora_tokino', 'tags': ['sora_tokino', '@sora_tokino', 'sora', 'tokino']}]
            >>> trends.topics
            >>> []
            ```
        
        # Lastest 
        I have to thanks for source code from 
        - dgnsrekt 
        
         I have make some awsome project :3
        
        à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸™à¸µà¹‰... à¸‚à¸­à¹„à¸›à¸”à¹‰à¸§à¸¢à¸ à¸²à¸ž à¹€à¸¡à¸™à¸•à¸±à¸§à¹€à¸­à¸‡à¸¥à¹ˆà¸°à¸à¸±à¸™ à¸›à¸¥. à¸¡à¸µà¸­à¸µà¸à¹€à¸¡à¸™à¸«à¸™à¸¶à¹ˆà¸‡
        
        ![Fubuki F R I E N D](https://media1.tenor.com/images/0d99bbdd3327e45bb49262bc25a34997/tenor.gif)
        
        
        # License
        
        MIT
        
Keywords: pytwitterscraper,twitterscraper,webscraper,apiscraper
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
