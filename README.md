# Twitter Scraper Python
Get data from twitter using REST API from Twitter :3

# Prerequisites
Before you begin, ensure you have met the following requirements:
    - Python 3.6 +
    - Internet Connnetion

# Installation
To install pytwitterscraper::
    
    pip install pytwitterscraper

# Usage 
First you have import libray pytwitterscraper::

    from pytwitterscraper import TwitterScraper

and call class object TwitterScraper::

    tw = TwitterScraper()

OK You have able to use pytwitterscraper

# Object Data

| Object Classes | Description |
| ------ | ------ |
| get_profile(name) | Get Profile from Twitter |
| get_tweets(id,count=20) | Get List Tweet from Profille Twitter By ID |
| get_tweetinfo(id,count=20) | Get Tweet Information By ID |
| get_tweetcomments(id) | Get Tweet Comments By ID **Top 10 Comment** | 
| get_trends() |        Get Trend Hashtags **Detect with IP Location**       |
| searchkeywords(query) | Search Keyworld With Users and Topics |

# Example Code
1. Get Profile **Example : I want get profile from Shirakami Fubuki** :
    ```py 
    >>> from pytwitterscraper import TwitterScraper
    >>> tw = TwitterScraper()
    >>> profile = tw.get_profile("shirakamifubuki")
    >>> profile.__dict__
    >>> {'id': '997786053124616192', 'name': 'ÁôΩ‰∏ä„Éï„Éñ„Ç≠@ShirakamiFubuki', 'screenname': 'shirakamifubuki', 'url': 'https://twitter.com/shirakamifubuki', 'description': 'Vtuber‰∫ãÂãôÊâÄ„Éõ„É≠„É©„Ç§„Éñ„Éó„É≠„ÉÄ„ÇØ„Ç∑„Éß„É≥/1ÊúüÁîüÁôΩ‰∏ä„Éï„Éñ„Ç≠ü¶ä‚ùñÊãÖÂΩìÁµµÂ∏´:Âá™ÁôΩ„Åø„Å®@lemon_mito „Äê„ÉÑ„Ç§ÊãÖÂΩì„Äëü¶ä„ÅØÈªí‰∏äüåΩ„ÅØ„É¶„Éã„Ç≥„É≥ „ÄêÁµµ„ÄëÔºÉÁµµ„Éï„Éñ„Ç≠ „ÄêÁîüÊîæÈÄÅ„Äë#„Éï„Éñ„Ç≠ch „ÄêÂàá„ÇäÊäú„Åç„Äë#„Éï„ÉñÂàá„Çä„Äê„Çπ„Ç±„Ç∏„É•„Éº„É´„Äë#ÁôΩ‰∏äÂºèÊâãÊäú„Åç„Çπ„Ç±„Ç∏„É•„Éº„É´', 'verifed': False, 'follower': 588788, 'following': 667, 'extended_url': 'https://t.co/R9TNhC7sPO', 'tweet': 75686, 'media': 9118, 'profileurl': 'https://pbs.twimg.com/profile_images/1322559849872334850/G2vq3G01.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_banners/997786053124616192/1594284737', 'createat': datetime.datetime(2018, 5, 19, 10, 28, 27, tzinfo=datetime.timezone.utc)}
    ```

2. Get Tweet **Example : I want get tweets from Shirakami Fubuki** :
    ```py 
    >>> from pytwitterscraper import TwitterScraper
    >>> tw = TwitterScraper()
    >>> tweets = tw.get_tweets(997786053124616192, count=3)
    >>> tweets.contents
    >>> [{'id': 1313103613204467712, 'created_at': datetime.datetime(2020, 10, 5, 13, 7, 52, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': '‚ú®ÁôΩ‰∏ä„Éï„Éñ„Ç≠„ÅäË™ïÁîüÊó•Ë®òÂøµ„Éú„Ç§„ÇπÔºÜ„Ç∞„ÉÉ„Ç∫‚ú®„Åä„Çã„ÇÑ„Çì„Åë„ÅÆ„Å¨„ÅÑ„Åê„Çã„Åø„ÅÆÂ§¢„ÅåÂè∂„ÅÑ„Åæ„Åó„Åü„Åù„Åó„Å¶ÊπØÂëë„ÇÇ„ÅÑ„Å§„Åã‰Ωú„Çä„Åü„ÅÑ„Å®Ë®Ä„Å£„Å¶„ÅüÂ§¢„ÅåÂè∂„ÅÑ„Åæ„Åó„ÅüÂ§¢„ÅåÊ≤¢Â±±Ë©∞„Åæ„Å£„Åü„Ç∞„ÉÉ„Ç∫ÈÅî„Åß„Åô„Çà„Çç„Åó„Åè„Åä„Å≠„Åå„ÅÑ„Åó„Åæ„ÅôüåΩüîΩË≥ºÂÖ•„ÅØ„Ç≥„ÉÅ„É©üîΩ‚Ä¶ https://t.co/ZksPkhYQI2', 'hashtags': [], 'media': [], 'urls': [{'url': 'https://t.co/ZksPkhYQI2'}], 'likes': 8656, 'relay': 0, 'retweet': 2329}, {'id': 1325440832795635713, 'created_at': datetime.datetime(2020, 11, 8, 14, 11, 34, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': '‚è∞ÔºíÔºïÊôÇ„Åã„Çâ\u3000„Éù„É´„Éù„É´„Å®‰∏ÄÁ∑í„Å´ÂπΩÈúäË™ø Êüª„ÅÑ„Åè„Åì„Å®„Å´„Å™„Å£„Åü„Çà„Éº„ÉºÔºÅÔºÅÔºÅÔºÅ‚ú®‰ªä„ÇΩ„É≠„ÅßÈ†ëÂºµ„Å£„Å¶„Çã„Åø„Åü„ÅÑ„Åû(^„Éªœâ„Éª^¬ß)Ôæâ„ÄêPhasmophobia„Äë Êú¨\u3000Áâ©\u3000„ÅÆ\u3000ÁãÇ\u3000Ê∞ó „ÄêÂ∞æ‰∏∏„Éù„É´„Ç´/„Éõ„É≠„É©„Ç§„Éñ„Äë https://t.co/MO7Xug3chb @YouTube„Çà„Çä', 'hashtags': [], 'media': [], 'urls': [{'url': 'https://t.co/MO7Xug3chb'}], 'likes': 1448, 'relay': 0, 'retweet': 254}, {'id': 1325458019069538304, 'created_at': datetime.datetime(2020, 11, 8, 15, 19, 52, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': '‚è∞ÔºíÔºïÊôÇ„Åã„ÇâÔºÅÔºÅÔºÅÔºÅÁ™ÅÁô∫ÔºÅ„Ç≠„ÉÑ„ÉçÂ±û„Å´„Çà„Çãüé™üåΩ‚ú®‚ú®Phasmophobia‚ú®‚ú®ÂÖàËº©Ë™øÊüªÂì°„Å®„Åó„Å¶Âºï„Å£Âºµ„Å£„Å¶„ÅÑ„Åè„Åû„Åâ„Åä„Åä„Å£ÔºÅ„Éù„É´„Éù„É´„ÇÇ‰∏äÊâã„Åè„Å™„Å£„Å¶„Çã„ÅÆ„ÅßÔºÅÔºí‰∫∫„Åß„Éó„É≠Ë™øÊüª„Åó„Å´„ÅÑ„Åè„Åû„Åâ„Åâ„Åä„ÅÑ„Å£ÔºÅÔºÅÔºÅüîΩÂæÖÊ©ü„Åó„Å¶„Åä„Çã„ÅãüîΩ‚Ä¶ https://t.co/2vUfw2RyY6', 'hashtags': [], 'media': [], 'urls': [{'url': 'https://t.co/2vUfw2RyY6'}], 'likes': 1707, 'relay': 0, 'retweet': 350}]
    ```

3. Get Tweet Info **Example : I want to get info ID Tweet 1324993735248109568** ::
    ```py
    >>> from pytwitterscraper import TwitterScraper
    >>> tw = TwitterScraper()
    >>> twinfo = tw.get_tweetinfo(1324993735248109568)
    >>> twinfo.contents
    >>> {'id': 1324993735248109568, 'created_at': datetime.datetime(2020, 11, 7, 8, 34, 58, tzinfo=datetime.timezone.utc), 'lang': 'ja', 'text': '‚è∞ÔºíÔºêÊôÇ„Åã„Çâ„Åß„Åô‰ªäÊó•„ÅÆ„ÅäÁ•ù„ÅÑ„ÅØÔºíÔºêÊôÇ„Åã„Çâ„Åß„ÅôÔºÅ‚ú®ÔºíÔºëÊôÇ„ÅØÔºïÊúüÁîü„Ç≥„É©„Éú„Åø„Åü„ÅÑ„Åã„ÇâÁöÜ„Åß„Åø„Çà„Éº„Å£üåΩ100‰∏á‰∫∫„Çí„Åø„Çì„Å™„Åß„ÅäÁ•ù„ÅÑ„Åô„Çã„ÇÑ„Éº„Å§üîΩ„ÅÑ„Å§„ÇÇ„ÅÇ„Çä„Åå„Å®„Å£üîΩ https://t.co/JV5IW889AE #„Éï„Éñ„Ç≠ch https://t.co/KSGTLDdnt3', 'hashtags': ['„Éï„Éñ„Ç≠ch'], 'media': [], 'urls': [], 'likes': 4204, 'relay': 0, 'retweet': 771}
    ```

4. Get Tweet Comments **Example : I want to get comments from ID Tweet 1324993735248109568** ::
    ```py
    >>> from pytwitterscraper import TwitterScraper
    >>> tw = TwitterScraper()
    >>> twcomments = tw.get_tweetcomments(1324993735248109568)
    >>> twcomments.contents
    >>> [{'id': 1324993789363056641, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 11, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ‰∫ÜËß£„Åß„ÅôÔºÅÔºÅ', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993879691599876, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 32, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ‰∫ÜËß£„Åß„ÅôÔºÅ', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993879611904000, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 32, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ü•∞ü•∞ü•∞ü•∞ü•∞ü•∞', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993804059897857, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 14, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki „Çä„Çá„Å¥ÔºÅ', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993901317529600, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 37, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki „Çä„Çá„Å¥ÔºÅ', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993889401413632, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 35, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki „Çä„Çá„Å¥ÔºÅ', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993901900386304, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 38, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki Â°æ„ÅßË¶ã„Çå„Å≠„Éº', 'hashtags': [], 'media': [], 'urls': [], 'likes': 1, 'relay': 0, 'retweet': 0}, {'id': 1324993880912064512, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 33, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki „Çä„Çá„Å¥ÔºÅÔºÅ', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993849077297155, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 25, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki ‰∫ÜËß£„Åß„Åô„ÄúÔºÅ', 'hashtags': [], 'media': [], 'urls': [], 'likes': 0, 'relay': 0, 'retweet': 0}, {'id': 1324993855440052225, 'created_at': datetime.datetime(2020, 11, 7, 8, 35, 26, tzinfo=datetime.timezone.utc), 'comment': '@shirakamifubuki I love you fubuki', 'hashtags': [], 'media': [], 'urls': [], 'likes': 1, 'relay': 0, 'retweet': 0}]
    ```

5. Get Trend Twitter ::
    ```py
    >>> from pytwitterscraper import TwitterScraper
    >>> tw = TwitterScraper()
    >>> trends = tw.get_trends()
    >>> trends.content
    >>> [{'name': '#earthquake', 'description': None}, {'name': '#SundayMorning', 'description': 'Greeting a new day with grumpiness, enthusiasm, motivation and coffee'}, {'name': 'GOT7', 'description': None}, {'name': 'Newt', 'description': None}, {'name': '#SundayThoughts', 'description': 'Wisdom, inspiration and curiosity for your Sunday'}, {'name': '#sundayvibes', 'description': None}, {'name': '#AskFFT', 'description': None}, {'name': 'New Bedford', 'description': None}, {'name': 'Four Seasons Total Landscaping', 'description': "People express confusion after President Trump Tweets that a press conference will be held 'at Four Seasons Total Landscaping‚Äô"}, {'name': 'Britain', 'description': None}, {'name': 'Antonio Brown', 'description': None}, {'name': 'Bliss Corner', 'description': None}, {'name': 'Good Sunday', 'description': None}, {'name': 'Cape Cod', 'description': None}, {'name': 'Parler', 'description': None}, {'name': 'Rudy', 'description': None}, {'name': 'Football Sunday', 'description': None}, {'name': 'Romney', 'description': None}, {'name': 'Deejay Dallas', 'description': None}, {'name': 'NFL Sunday', 'description': None}, {'name': 'USGS', 'description': None}, {'name': 'Written', 'description': None}, {'name': 'Mike Williams', 'description': None}, {'name': 'Turtwig', 'description': None}, {'name': 'Marvin Jones', 'description': None}, {'name': 'Chark', 'description': None}, {'name': 'Jeudy', 'description': None}, {'name': 'Doherty', 'description': None}, {'name': 'Seahawks -3', 'description': None}, {'name': 'Kushner', 'description': None}]
    ```

6. Search Keyword 
    ```py
    >>> from pytwitterscraper import TwitterScraper
    >>> tw = TwitterScraper()
    >>> search = tw.searchkeywords("tokinosora")
    >>> trends.users
    >>> [{'name': 'ÊôÇÈáéÁ©∫‰∫∫', 'url': 'https://twitter.com/TokinoSorahito', 'profileurl': 'http://pbs.twimg.com/profile_images/480667036410863616/yeHCL21U_normal.png', 'bannerurl': 'https://pbs.twimg.com/profile_images/480667036410863616/yeHCL21U_normal.png', 'screen_name': 'TokinoSorahito', 'tags': ['tokinosorahito', '@tokinosorahito', ' ÊôÇÈáéÁ©∫‰∫∫']}, {'name': 'ÊôÇ„ÅÆÁ©∫', 'url': 'https://twitter.com/tokinosora', 'profileurl': 'http://pbs.twimg.com/profile_images/584402675506098176/InsS4pO1_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/584402675506098176/InsS4pO1_normal.jpg', 'screen_name': 'tokinosora', 'tags': ['tokinosora', '@tokinosora', 'ÊôÇ„ÅÆÁ©∫']}, {'name': '„ÅØ„Éº„Å®', 'url': 'https://twitter.com/tokinosora7nana', 'profileurl': 'http://pbs.twimg.com/profile_images/414496896229470208/65DNd-___normal.jpeg', 'bannerurl': 'https://pbs.twimg.com/profile_images/414496896229470208/65DNd-___normal.jpeg', 'screen_name': 'tokinosora7nana', 'tags': ['tokinosora7nana', '@tokinosora7nana', '„ÅØ„Éº„Å®']}, {'name': 'tokinosora111', 'url': 'https://twitter.com/tokinosora111', 'profileurl': 'http://pbs.twimg.com/profile_images/958098875058814976/jT0oYXLt_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/958098875058814976/jT0oYXLt_normal.jpg', 'screen_name': 'tokinosora111', 'tags': ['tokinosora111', '@tokinosora111']}, {'name': 'Tokinosora17', 'url': 'https://twitter.com/tokinosora17', 'profileurl': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'bannerurl': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'screen_name': 'tokinosora17', 'tags': ['tokinosora17', '@tokinosora17']}, {'name': 'ÊùæÈáé', 'url': 'https://twitter.com/tokinosora33', 'profileurl': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'bannerurl': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'screen_name': 'tokinosora33', 'tags': ['tokinosora33', '@tokinosora33', 'ÊùæÈáé']}, {'name': 'Ê≠§Â∏≥Êà∂ÂÅúÁî®‰∏≠', 'url': 'https://twitter.com/tokinosora0705', 'profileurl': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'bannerurl': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'screen_name': 'tokinosora0705', 'tags': ['tokinosora0705', '@tokinosora0705', 'Ê≠§Â∏≥Êà∂ÂÅúÁî®‰∏≠']}, {'name': 'ÂÆôËàπ-„Åù„Çâ„Åµ„Å≠-', 'url': 'https://twitter.com/tokinosorahune', 'profileurl': 'http://pbs.twimg.com/profile_images/749949021012172800/978S0ipS_normal.jpg', 'bannerurl': 'https://pbs.twimg.com/profile_images/749949021012172800/978S0ipS_normal.jpg', 'screen_name': 'tokinosorahune', 'tags': ['tokinosorahune', '@tokinosorahune', 'ÂÆôËàπ-„Åù„Çâ„Åµ„Å≠-']}]
    >>> trends.topics
    >>> []
    ```

# Lastest 
I have to thanks for source code from 
- dgnsrekt 

 I have make some awsome project :3

‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ô‡∏µ‡πâ... ‡∏Ç‡∏≠‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏û ‡πÄ‡∏°‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏•‡πà‡∏∞‡∏Å‡∏±‡∏ô

![Fubuki F R I E N D ](https://media1.tenor.com/images/0d99bbdd3327e45bb49262bc25a34997/tenor.gif)


# License

MIT
